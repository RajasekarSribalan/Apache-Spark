Hive

Creating tables and loading data

    Create database
    Create tables using text file format
    Make sure structure of data and the delimiters specified while create tables are same
    If so, one can load data into Hive table using load command


create database dgadiraju_retail_db_txt;
use dgadiraju_retail_db_txt;

create table orders (
  order_id int,
  order_date string,
  order_customer_id int,
  order_status string
) row format delimited fields terminated by ','
stored as textfile;

load data local inpath '/data/retail_db/orders' into table orders;

create table order_items (
  order_item_id int,
  order_item_order_id int,
  order_item_product_id int,
  order_item_quantity int,
  order_item_subtotal float,
  order_item_product_price float
) row format delimited fields terminated by ','
stored as textfile;

load data local inpath '/data/retail_db/order_items' into table order_items;

hive> dfs -ls /

hive> dfs -ls /data/retail_db/;
Found 6 items
drwxr-xr-x   - hduser supergroup          0 2018-12-19 06:43 /data/retail_db/categories
drwxr-xr-x   - hduser supergroup          0 2018-12-19 06:43 /data/retail_db/customers
drwxr-xr-x   - hduser supergroup          0 2018-12-19 06:43 /data/retail_db/departments
drwxr-xr-x   - hduser supergroup          0 2018-12-25 11:32 /data/retail_db/order_items
drwxr-xr-x   - hduser supergroup          0 2018-12-25 11:30 /data/retail_db/orders
drwxr-xr-x   - hduser supergroup          0 2018-12-19 06:43 /data/retail_db/products



****** hive landugae manual for all comamds during exam


Creating tables and insert data

    Hive supports other file formats
        avro
        orc
        parquet
        sequencefile
        and more
    When we use special file formats, most likely
        Create staging table where structure matches data
        Create table with the format you are interested in
        Use insert command to get data from stage table into final table




For other file formats,we need to use "insert" commands.
When these formats are used,delimiter is not required to be given in the table creation command bcz it stores metadata.

describe orders;
describe extended orders;
describe formatted orders;


*** Default file format of ORC

SerDe Library:          org.apache.hadoop.hive.ql.io.orc.OrcSerde
InputFormat:            org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
OutputFormat:           org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat


To use custom file format, refer to Hive language manual 

We can use INPUTFORMAT


file_format:
  : SEQUENCEFILE
  | TEXTFILE    -- (Default, depending on hive.default.fileformat configuration)
  | RCFILE      -- (Note: Available in Hive 0.6.0 and later)
  | ORC         -- (Note: Available in Hive 0.11.0 and later)
  | PARQUET     -- (Note: Available in Hive 0.13.0 and later)
  | AVRO        -- (Note: Available in Hive 0.14.0 and later)
  | JSONFILE    -- (Note: Available in Hive 4.0.0 and later)
  | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname
  
  
create database dgadiraju_retail_db_orc;
use dgadiraju_retail_db_orc;

create table orders (
  order_id int,
  order_date string,
  order_customer_id int,
  order_status string
) stored as orc;

insert into table orders select * from dgadiraju_retail_db_txt.orders;

create table order_items (
  order_item_id int,
  order_item_order_id int,
  order_item_product_id int,
  order_item_quantity int,
  order_item_subtotal float,
  order_item_product_price float
) stored as orc;

insert into table order_items select * from dgadiraju_retail_db_txt.order_items;


******************** Spark SQL â€“ Functions

Spark SQL or Hive have bunch of functions to apply transformations on the data.

    String manipulating functions
    Data manipulating functions
    Type cast functions
    Functions to deal with nulls
    Aggregating functions
    Conditional expressions
    and more


to list functions suported by hive,

hive> show functions
    > ;
OK
!
!=
$sum0
%
&
*
+
-
/
<
<=
<=>
<>
=
==
>
>=
^
abs
acos
add_months
aes_decrypt



hive> describe function avg;
OK
avg(x) - Returns the mean of a set of numbers
Time taken: 0.019 seconds, Fetched: 1 row(s)
hive> describe function sum;
OK
sum(x) - Returns the sum of a set of numbers
Time taken: 0.009 seconds, Fetched: 1 row(s)
hive> 


To test a function,

hive> select length('hello raj');
OK
9
Time taken: 0.212 seconds, Fetched: 1 row(s)


************* Manipulating Strings ****************

hive> describe function substr
    > ;
OK
substr(str, pos[, len]) - returns the substring of str that starts at pos and is of length len orsubstr(bin, pos[, len]) - returns the slice of byte array that starts at pos and is of length len
Time taken: 0.015 seconds, Fetched: 1 row(s)
hive> describe function substring;
OK
substring(str, pos[, len]) - returns the substring of str that starts at pos and is of length len orsubstring(bin, pos[, len]) - returns the slice of byte array that starts at pos and is of length len
Time taken: 0.021 seconds, Fetched: 1 row(s)
hive> describe function substr;
OK
substr(str, pos[, len]) - returns the substring of str that starts at pos and is of length len orsubstr(bin, pos[, len]) - returns the slice of byte array that starts at pos and is of length len
Time taken: 0.009 seconds, Fetched: 1 row(s)
hive> select 'Hello world, how are you'
    > ;
OK
Hello world, how are you
Time taken: 0.206 seconds, Fetched: 1 row(s)
hive> select 'Hello world, how are you';
OK
Hello world, how are you
Time taken: 0.203 seconds, Fetched: 1 row(s)
hive> select substr('Hello world, how are you',14);
OK
how are you
Time taken: 0.208 seconds, Fetched: 1 row(s)
hive> select substr('Hello world, how are you',7,5);
OK
world
Time taken: 0.143 seconds, Fetched: 1 row(s)
hive> select substr('Hello world, how are you',-3);
OK
you
Time taken: 0.509 seconds, Fetched: 1 row(s)
hive> select substr('Hello world, how are you',-7,3);
OK
are
Time taken: 0.201 seconds, Fetched: 1 row(s)

hive> select instr('Hello world, how are you',' ');
OK
6
Time taken: 0.202 seconds, Fetched: 1 row(s)
hive> select instr('Hello world, how are you','world');
OK
7
Time taken: 0.085 seconds, Fetched: 1 row(s)
hive> select instr('Hello world, how are you','h');
OK
14
Time taken: 0.2 seconds, Fetched: 1 row(s)
hive> select instr('Hello world, how are you','H');
OK
1
Time taken: 0.206 seconds, Fetched: 1 row(s)
hive> select like('Hello world, how are you','h');

hive> select 'Hello world, how are you' like 'Hello%';
OK
true
Time taken: 0.21 seconds, Fetched: 1 row(s)
hive> select 'Hello world, how are you' like '%Hello%';
OK
true
Time taken: 0.135 seconds, Fetched: 1 row(s)
hive> select 'Hello world, how are you' like '%you%';
OK
true
Time taken: 0.209 seconds, Fetched: 1 row(s)
hive> select 'Hello world, how are you' like '%YOU%';
OK
false
Time taken: 0.359 seconds, Fetched: 1 row(s)
hive> select length('Hello world, how are you');
OK
24
Time taken: 0.206 seconds, Fetched: 1 row(s)
hive> select lower('Hello world, how are you');
OK
hello world, how are you
Time taken: 0.208 seconds, Fetched: 1 row(s)
hive> select lcase('Hello world, how are you');
OK
hello world, how are you
Time taken: 0.201 seconds, Fetched: 1 row(s)
hive> select ucase('Hello world, how are you');
OK
HELLO WORLD, HOW ARE YOU
Time taken: 0.85 seconds, Fetched: 1 row(s)
hive> select upper('Hello world, how are you');
OK
HELLO WORLD, HOW ARE YOU
Time taken: 0.2 seconds, Fetched: 1 row(s)
hive> select initcap('Hello world, how are you');
OK
Hello World, How Are You
Time taken: 0.202 seconds, Fetched: 1 row(s)
hive> select '12';
OK
12
Time taken: 0.899 seconds, Fetched: 1 row(s)
hive> select cast('12' as int);
OK
12
Time taken: 0.224 seconds, Fetched: 1 row(s)
hive> select order_date from orders limit 20;
FAILED: SemanticException [Error 10001]: Line 1:23 Table not found 'orders'
hive> show tables;
OK
customers
Time taken: 0.129 seconds, Fetched: 1 row(s)
hive> use retails_db_txt;
FAILED: SemanticException [Error 10072]: Database does not exist: retails_db_txt
hive> show databases;
OK
default
dgadiraju_retail_db_orc
retail_db_txt
Time taken: 0.019 seconds, Fetched: 3 row(s)
hive> use retails_db_txt;
FAILED: SemanticException [Error 10072]: Database does not exist: retails_db_txt
hive> use retail_db_txt;
OK
Time taken: 0.009 seconds
hive> show tables;
OK
order_items
orders
Time taken: 0.017 seconds, Fetched: 2 row(s)
hive> select  order_date from orders limit 10;
OK
2013-07-25 00:00:00.0
2013-07-25 00:00:00.0
2013-07-25 00:00:00.0
2013-07-25 00:00:00.0
2013-07-25 00:00:00.0
2013-07-25 00:00:00.0
2013-07-25 00:00:00.0
2013-07-25 00:00:00.0
2013-07-25 00:00:00.0
2013-07-25 00:00:00.0
Time taken: 0.211 seconds, Fetched: 10 row(s)
hive> select  substr(order_date,6,2) from orders limit 10;
OK
07
07
07
07
07
07
07
07
07
07
Time taken: 0.699 seconds, Fetched: 10 row(s)
hive> select  cast(substr(order_date,6,2) as int0 from orders limit 10;

hive> select  cast(substr(order_date,6,2) as int) from orders limit 10;
OK
7
7
7
7
7
7
7
7
7
7
Time taken: 0.299 seconds, Fetched: 10 row(s)
hive> select  substr(order_date,6,2) from orders limit 10;
OK
07
07
07
07
07
07
07
07
07
07
Time taken: 0.133 seconds, Fetched: 10 row(s)
hive> select cast("hello" as int)
    > ;
OK
NULL
Time taken: 0.199 seconds, Fetched: 1 row(s)
hive> select split("hello word hw are you",' ');
OK
["hello","word","hw","are","you"]
Time taken: 0.235 seconds, Fetched: 1 row(s)
hive> select index(split("hello word hw are you",' '),4);
OK
you
Time taken: 0.208 seconds, Fetched: 1 row(s)
hive> select index(split("hello word hw are you",' '),0);
OK
hello
Time taken: 0.211 seconds, Fetched: 1 row(s)
hive> 


rlike

select 'Hello workd,how r you' rlike '%you%';  -> this will not work.This will work only for regex

lpad
rpad

hive (rajasekar_retail_db_txt)> select lpad(123,5,0);
OK
00123
Time taken: 0.308 seconds, Fetched: 1 row(s)
hive (rajasekar_retail_db_txt)> select rpad(123,5,0);
OK
12300



********************** Manipulating Dates  **************************

https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-DateFunctions


hduser@raj-Lenovo-Y50-70:/usr/local/apache-hive-2.1.0-bin$ hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/apache-hive-2.1.0-bin/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/local/apache-hive-2.1.0-bin/lib/hive-common-2.1.0.jar!/hive-log4j2.properties Async: true
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> select current_date;
OK
2018-12-25
Time taken: 1.821 seconds, Fetched: 1 row(s)
hive> select current_timstamp;
FAILED: SemanticException [Error 10004]: Line 1:7 Invalid table alias or column reference 'current_timstamp': (possible column names are: )
hive> select current_timestamp;
OK
2018-12-25 12:46:18.401
Time taken: 0.231 seconds, Fetched: 1 row(s)
hive> select date_format(current_date,YYYY);
FAILED: SemanticException [Error 10004]: Line 1:32 Invalid table alias or column reference 'YYYY': (possible column names are: )
hive> select date_format(current_date,'y');
OK
2018
Time taken: 0.21 seconds, Fetched: 1 row(s)
hive> select date_format(current_date,'m');
OK
0
Time taken: 0.093 seconds, Fetched: 1 row(s)
hive> select date_format(current_date,'d');
OK
25
Time taken: 0.14 seconds, Fetched: 1 row(s)
hive> select date_format(current_date,'D');
OK
359
Time taken: 0.204 seconds, Fetched: 1 row(s)
hive> select day(current_date);
OK
25
Time taken: 0.125 seconds, Fetched: 1 row(s)
hive> select dayofmonth(current_date);
OK
25
Time taken: 0.204 seconds, Fetched: 1 row(s)



**************** Aggregating Functions *****************

select count(1) from orders;
select sum(order_item_subtotal) from orders;

 select to_unix_timestamp(current_date);
OK
1556164800
Time taken: 0.378 seconds, Fetched: 1 row(s)
hive (rajasekar_retail_db_txt)> select to_unix_timestamp(current_date);
OK
1556164800
Time taken: 0.283 seconds, Fetched: 1 row(s)
hive (rajasekar_retail_db_txt)> select from_unix_timestamp(1556164800)
                              > ;
FAILED: SemanticException [Error 10011]: Line 1:7 Invalid function 'from_unix_timestamp'
hive (rajasekar_retail_db_txt)> select from_unixtime(1556164800);
OK
2019-04-25 00:00:00
Time taken: 0.45 seconds, Fetched: 1 row(s)



******************** Case Statement ************


case
nvl

kind of using IF condition like in programing


describe function case;
OK
CASE a WHEN b THEN c [WHEN d THEN e]* [ELSE f] END - When a = b, returns c; when a = d, return e; else return f
Time taken: 0.018 seconds, Fetched: 1 row(s)


select order_status,
       case  
            when order_status IN ('CLOSED', 'COMPLETE') then 'No Action' 
            when order_status IN ('ON_HOLD', 'PAYMENT_REVIEW', 'PENDING', 'PENDING_PAYMENT', 'PROCESSING') then 'Pending Action'
            else 'Risky'
end from orders limit 10;



***************** Spark SQL â€“ Standard Transformations *********************

Row level transformation

To take year and month, and concat both to form a string

e.g., date - 2017-05-31 00.00.00.0

substr(1,4) gives 2017
substr(6,2) gives 05
concat() gives 201705

select concat(substr(order_date,1,4),substr(order_date,6,2)) from orders limit 10;

hive (rajasekar_retail_db_txt)> select concat(substr(order_date,1,4),substr(order_date,6,2)) from orders limit 10;
OK
201307
201307
201307
201307
201307
201307
201307
201307
201307
201307

select cast(concat(substr(order_date,1,4),substr(order_date,6,2))  as int )from orders limit 10;


****** JOIn ****

select o.*, c.* from customers c left outer join orders o
on o.order_customer_id = c.customer_id
limit 10;

select count(1) from orders o inner join customers c
on o.order_customer_id = c.customer_id;

select count(1) from customers c left outer join orders o
on o.order_customer_id = c.customer_id;

select c.* from customers c left outer join orders o
on o.order_customer_id = c.customer_id
where o.order_customer_id is null;


********* Aggregations ****************


select o.order_id, o.order_date, o.order_status, round(sum(oi.order_item_subtotal), 2) order_revenue
from orders o join order_items oi
on o.order_id = oi.order_item_order_id
where o.order_status in ('COMPLETE', 'CLOSED')
group by o.order_id, o.order_date, o.order_status
having sum(oi.order_item_subtotal) >= 1000;

*******  Sorting ******

order_by *Column name"

defaut is  asc
desc

select o.order_id, o.order_date, o.order_status, round(sum(oi.order_item_subtotal), 2) order_revenue
from orders o join order_items oi
on o.order_id = oi.order_item_order_id
where o.order_status in ('COMPLETE', 'CLOSED')
group by o.order_id, o.order_date, o.order_status
having sum(oi.order_item_subtotal) >= 1000
order by o.order_date,order_revenue desc;


sort by *Column name"

To sort based on each date

select o.order_id, o.order_date, o.order_status, round(sum(oi.order_item_subtotal), 2) order_revenue
from orders o join order_items oi
on o.order_id = oi.order_item_order_id
where o.order_status in ('COMPLETE', 'CLOSED')
group by o.order_id, o.order_date, o.order_status
having sum(oi.order_item_subtotal) >= 1000
distribute b o.oder_date sort by o.order_date,order_revenue desc;



******** SET operations ******

union
union all


Spark SQL â€“ Processing data using Data Frames

Let us get into details related to Data Frames. Data Frames can be created from

    RDD, by using toDF function
    We can register Data Frame as temp table and start running queries against it
    Querying hive tables (which is already explored)
    Querying tables from remote databases using JDBC

Create Data Frame and Register as temp table

Here are the steps to create data frame and run queries against it

    Read data from HDFS
    Apply map transformation to convert each record into tuple
    Use toDF function to convert RDD into Data Frame
    Register Data Frame as temp table
    Run queries against temp table using sqlContext.sql

val ordersRDD = sc.textFile("/public/retail_db/orders")
val ordersDF = ordersRDD.map(order => {
  (order.split(",")(0).toInt, order.split(",")(1), order.split(",")(2).toInt, order.split(",")(3))
}).toDF("order_id", "order_date", "order_customer_id", "order_status")

ordersDF.registerTempTable("orders")
sqlContext.sql("select order_status, count(1) count_by_status from orders group by order_status").show()

sqlContext.sql("use dgadiraju_retail_db_orc")
val productsRaw = scala.io.Source.fromFile("/data/retail_db/products/part-00000").getLines.toList
val productsRDD = sc.parallelize(productsRaw)
val productsDF = productsRDD.map(product => {
  (product.split(",")(0).toInt, product.split(",")(2))
}).
toDF("product_id", "product_name")

productsDF.registerTempTable("products")

sqlContext.sql("select * from products").show
